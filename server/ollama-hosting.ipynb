{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Download and install ollama to the system\n!curl https://ollama.ai/install.sh | sh","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!echo 'debconf debconf/frontend select Noninteractive' | sudo debconf-set-selections","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:22:27.508447Z","iopub.execute_input":"2025-03-25T18:22:27.508777Z","iopub.status.idle":"2025-03-25T18:22:27.922383Z","shell.execute_reply.started":"2025-03-25T18:22:27.508744Z","shell.execute_reply":"2025-03-25T18:22:27.921180Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install aiohttp pyngrok","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!sudo apt-get update\n!sudo apt-get install -y cuda-drivers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport asyncio\n\n# Set LD_LIBRARY_PATH to the system NVIDIA library \nos.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:25:36.511450Z","iopub.execute_input":"2025-03-25T18:25:36.511743Z","iopub.status.idle":"2025-03-25T18:25:36.515902Z","shell.execute_reply.started":"2025-03-25T18:25:36.511717Z","shell.execute_reply":"2025-03-25T18:25:36.515018Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#set OLLAMA_HOST=ngrok_url\n#ollama pull nomic-embed-text\n#ollama pull deepseek-r1:14b\n#ollama pull gemma3:4b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:25:36.516634Z","iopub.execute_input":"2025-03-25T18:25:36.516871Z","iopub.status.idle":"2025-03-25T18:25:36.529994Z","shell.execute_reply.started":"2025-03-25T18:25:36.516850Z","shell.execute_reply":"2025-03-25T18:25:36.529228Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"async def run_process(cmd):\n  print('>>> starting', *cmd)\n  p = await asyncio.subprocess.create_subprocess_exec(\n      *cmd,\n      stdout=asyncio.subprocess.PIPE,\n      stderr=asyncio.subprocess.PIPE,\n  )\n\n  async def pipe(lines):\n    async for line in lines:\n      print(line.strip().decode('utf-8'))\n\n  await asyncio.gather(\n      pipe(p.stdout),\n      pipe(p.stderr),\n  )\n\n#register an account at ngrok.com and create an authtoken and place it here\nawait asyncio.gather(\n    run_process(['ngrok', 'config', 'add-authtoken','2kCekaSMtCO84IqCbeySTIhVUcO_7punZJwo6hLLKywtwrcAN'])\n)\n\nawait asyncio.gather(\n    run_process(['ollama', 'serve']),\n    run_process(['ngrok', 'http', '--log', 'stderr', '11434', '--host-header', 'localhost:11434'])\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}